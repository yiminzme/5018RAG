python src/read_generation_results.py     --output_dir data/100out_baseline/3doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type classic     --use_random False     --use_adore False     --gold_position 1     --num_documents_in_context 3     --get_documents_without_answer True > eval/1/100out_3.out
python src/read_generation_results.py     --output_dir data/100out_baseline/4doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type classic     --use_random False     --use_adore False     --gold_position 2     --num_documents_in_context 4     --get_documents_without_answer True > eval/1/100out_4.out
python src/read_generation_results.py     --output_dir data/100out_baseline/5doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type classic     --use_random False     --use_adore False     --gold_position 2     --num_documents_in_context 5     --get_documents_without_answer True > eval/1/100out_5.out
python src/read_generation_results.py     --output_dir data/100out_baseline/6doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type classic     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 6     --get_documents_without_answer True > eval/1/100out_6.out
python src/read_generation_results.py     --output_dir data/100out_baseline/7doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type classic     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/1/100out_7.out
python src/read_generation_results.py     --output_dir data/100out_baseline/8doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type classic     --use_random False     --use_adore False     --gold_position 4     --num_documents_in_context 8     --get_documents_without_answer True > eval/1/100out_8.out
python src/read_generation_results.py     --output_dir data/100out_baseline/9doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type classic     --use_random False     --use_adore False     --gold_position 4     --num_documents_in_context 9     --get_documents_without_answer True > eval/1/100out_9.out
python src/read_generation_results.py     --output_dir data/100out_baseline/10doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type classic     --use_random False     --use_adore False     --gold_position 5     --num_documents_in_context 10     --get_documents_without_answer True > eval/1/100out_10.out
python src/read_generation_results.py     --output_dir data/100out_baseline/11doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type classic     --use_random False     --use_adore False     --gold_position 5     --num_documents_in_context 11     --get_documents_without_answer True > eval/1/100out_11.out


python src/read_generation_results.py     --output_dir data/100out_baseline/7doc_gold0     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type classic     --use_random False     --use_adore False     --gold_position 0     --num_documents_in_context 7     --get_documents_without_answer True > eval/3/100out_gold_0.out
python src/read_generation_results.py     --output_dir data/100out_baseline/7doc_gold1     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type classic     --use_random False     --use_adore False     --gold_position 1     --num_documents_in_context 7     --get_documents_without_answer True > eval/3/100out_gold_1.out
python src/read_generation_results.py     --output_dir data/100out_baseline/7doc_gold2     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type classic     --use_random False     --use_adore False     --gold_position 2     --num_documents_in_context 7     --get_documents_without_answer True > eval/3/100out_gold_2.out
python src/read_generation_results.py     --output_dir data/100out_baseline/7doc_gold3     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type classic     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/3/100out_gold_3.out
python src/read_generation_results.py     --output_dir data/100out_baseline/7doc_gold4     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type classic     --use_random False     --use_adore False     --gold_position 4     --num_documents_in_context 7     --get_documents_without_answer True > eval/3/100out_gold_4.out
python src/read_generation_results.py     --output_dir data/100out_baseline/7doc_gold5     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type classic     --use_random False     --use_adore False     --gold_position 5     --num_documents_in_context 7     --get_documents_without_answer True > eval/3/100out_gold_5.out
python src/read_generation_results.py     --output_dir data/100out_baseline/7doc_gold6     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type classic     --use_random False     --use_adore False     --gold_position 6     --num_documents_in_context 7     --get_documents_without_answer True > eval/3/100out_gold_6.out
