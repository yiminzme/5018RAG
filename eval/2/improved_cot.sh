python src/read_generation_results_improved.py     --output_dir data/gen_res_cot_thr0     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/improved_cot_0_0.out
python src/read_generation_results_improved.py     --output_dir data/gen_res_cot_thr0_1     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/improved_cot_0_1.out
python src/read_generation_results_improved.py     --output_dir data/gen_res_cot_thr0_2     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/improved_cot_0_2.out
python src/read_generation_results_improved.py     --output_dir data/gen_res_cot_thr0_3     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/improved_cot_0_3.out
python src/read_generation_results_improved.py     --output_dir data/gen_res_cot_thr0_4     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/improved_cot_0_4.out
python src/read_generation_results_improved.py     --output_dir data/gen_res_cot_thr0_5     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/improved_cot_0_5.out
python src/read_generation_results_improved.py     --output_dir data/gen_res_cot_thr0_6     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/improved_cot_0_6.out
python src/read_generation_results_improved.py     --output_dir data/gen_res_cot_thr0_7     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/improved_cot_0_7.out
python src/read_generation_results_improved.py     --output_dir data/gen_res_cot_thr0_8     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/improved_cot_0_8.out
python src/read_generation_results_improved.py     --output_dir data/gen_res_cot_thr0_9     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/improved_cot_0_9.out
python src/read_generation_results_improved.py     --output_dir data/gen_res_cot_thr1_0     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/improved_cot_1_0.out
