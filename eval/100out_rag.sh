python src/read_generation_results_improved.py     --output_dir data/100out_improved/3doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 1     --num_documents_in_context 3       --get_documents_without_answer True > eval/1/100out_rag_3.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/4doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 2     --num_documents_in_context 4       --get_documents_without_answer True > eval/1/100out_rag_4.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/5doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 2     --num_documents_in_context 5       --get_documents_without_answer True > eval/1/100out_rag_5.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/6doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 6       --get_documents_without_answer True > eval/1/100out_rag_6.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/7doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7       --get_documents_without_answer True > eval/1/100out_rag_7.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/8doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 4     --num_documents_in_context 8       --get_documents_without_answer True > eval/1/100out_rag_8.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/9doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 4     --num_documents_in_context 9       --get_documents_without_answer True > eval/1/100out_rag_9.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/10doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 5     --num_documents_in_context 10     --get_documents_without_answer True > eval/1/100out_rag_10.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/11doc     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 5     --num_documents_in_context 11     --get_documents_without_answer True > eval/1/100out_rag_11.out

python src/read_generation_results_improved.py     --output_dir data/100out_improved/thr0      --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/100out_rag_0_0.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/thr0_1    --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/100out_rag_0_1.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/thr0_2    --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/100out_rag_0_2.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/thr0_3    --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/100out_rag_0_3.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/thr0_4    --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/100out_rag_0_4.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/thr0_5    --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/100out_rag_0_5.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/thr0_6    --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/100out_rag_0_6.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/thr0_7    --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/100out_rag_0_7.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/thr0_8    --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/100out_rag_0_8.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/thr0_9    --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/100out_rag_0_9.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/thr1_0    --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/2/100out_rag_1_0.out

python src/read_generation_results_improved.py     --output_dir data/100out_improved/7doc_gold0     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 0     --num_documents_in_context 7     --get_documents_without_answer True > eval/3/100out_rag_gold_0.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/7doc_gold1     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 1     --num_documents_in_context 7     --get_documents_without_answer True > eval/3/100out_rag_gold_1.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/7doc_gold2     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 2     --num_documents_in_context 7     --get_documents_without_answer True > eval/3/100out_rag_gold_2.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/7doc_gold3     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 3     --num_documents_in_context 7     --get_documents_without_answer True > eval/3/100out_rag_gold_3.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/7doc_gold4     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 4     --num_documents_in_context 7     --get_documents_without_answer True > eval/3/100out_rag_gold_4.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/7doc_gold5     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 5     --num_documents_in_context 7     --get_documents_without_answer True > eval/3/100out_rag_gold_5.out
python src/read_generation_results_improved.py     --output_dir data/100out_improved/7doc_gold6     --llm_id meta-llama/Llama-2-7b-chat-hf     --use_test False     --prompt_type improved     --use_random False     --use_adore False     --gold_position 6     --num_documents_in_context 7     --get_documents_without_answer True > eval/3/100out_rag_gold_6.out
