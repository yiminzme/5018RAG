Loading LLM...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.66s/it]
LLM loaded
Loading corpus and search results...
Corpus and search results loaded
Loading prompt dataset...
Prompt dataset loaded
INFO:
DATA: data/154_train_dataset.json
MODEL: meta-llama/Llama-2-7b-chat-hf
USE RANDOM IN CONTEXT: False
USE ADORE: False
GOLD POSITION: 3
NUM DOCUMENTS IN CONTEXT: 7
DOCUMENTS WITHOUT ANSWER: True
BATCH SIZE: 18
SAVE EVERY: 250
  0%|          | 0/9 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
 11%|█         | 1/9 [01:46<14:12, 106.54s/it] 22%|██▏       | 2/9 [05:42<21:18, 182.60s/it] 33%|███▎      | 3/9 [09:44<20:59, 209.92s/it] 44%|████▍     | 4/9 [12:24<15:49, 189.98s/it] 56%|█████▌    | 5/9 [18:47<17:18, 259.55s/it] 67%|██████▋   | 6/9 [21:50<11:40, 233.61s/it] 78%|███████▊  | 7/9 [28:11<09:23, 281.73s/it] 89%|████████▉ | 8/9 [31:43<04:19, 259.74s/it]Saving at 9...
100%|██████████| 9/9 [35:17<00:00, 245.34s/it]100%|██████████| 9/9 [35:17<00:00, 235.29s/it]
Directory:  data/gen_res/Llama-2-7b-chat-hf/train/classic/contriever/7_doc
I'm using the following files:  ['numdoc7_gold_at3_answerless_info_1.pkl', 'numdoc7_gold_at3_answerless_info_9.pkl']
ACCURACY:  0.2866
Precision: 1.0
Recall: 0.2865853658536585
F1 Score: 0.44549763033175355
