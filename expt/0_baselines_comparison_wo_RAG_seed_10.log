Loading LLM...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.87s/it]
LLM loaded
Loading prompt dataset...
Prompt dataset loaded
INFO:
ONLY QUERY
DATA: data/154_train_dataset.json
MODEL: meta-llama/Llama-2-7b-chat-hf
BATCH SIZE: 12
SAVE EVERY: 250
  0%|          | 0/13 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
  8%|▊         | 1/13 [00:01<00:20,  1.73s/it] 15%|█▌        | 2/13 [00:02<00:13,  1.24s/it] 23%|██▎       | 3/13 [00:03<00:10,  1.03s/it] 31%|███       | 4/13 [00:04<00:08,  1.01it/s] 38%|███▊      | 5/13 [00:05<00:07,  1.05it/s] 46%|████▌     | 6/13 [00:06<00:06,  1.09it/s] 54%|█████▍    | 7/13 [00:06<00:05,  1.12it/s] 62%|██████▏   | 8/13 [00:07<00:04,  1.25it/s] 69%|██████▉   | 9/13 [00:08<00:02,  1.35it/s] 77%|███████▋  | 10/13 [00:08<00:02,  1.38it/s] 85%|████████▍ | 11/13 [00:09<00:01,  1.31it/s] 92%|█████████▏| 12/13 [00:10<00:00,  1.25it/s]Saving at 13...
100%|██████████| 13/13 [00:11<00:00,  1.39it/s]100%|██████████| 13/13 [00:11<00:00,  1.17it/s]
Directory:  data/gen_res/Llama-2-7b-chat-hf/train/only_query/
I'm using the following files:  ['only_query_info_1.pkl', 'only_query_info_13.pkl']
ACCURACY:  0.1037
Precision: 1.0
Recall: 0.10365853658536585
F1 Score: 0.1878453038674033
